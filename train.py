import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
from torchvision import transforms
from torchmetrics import (
    StructuralSimilarityIndexMeasure,
    PeakSignalNoiseRatio,
)
from rich.progress import track
from dataset import SplitImageDataset, ImageDataset
from architectures import (
    GENERATORS,
    DISCRIMINATORS,
)


if torch.cuda.is_available():
    device = torch.device("cuda")
elif torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    device = torch.device("cpu")

torch.manual_seed(42)

# Performance metrics used for report.
ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)
psnr = PeakSignalNoiseRatio(data_range=1.0).to(device)


def validate(
    generator: nn.Module,
    val_data: ImageDataset
) -> (torch.Tensor, torch.Tensor):
    """Evaluates the generator on the validation data and returns the mean SSIM
    and pSNR."""

    generator.eval()
    ssims = []
    psnrs = []

    with torch.no_grad():
        for x, y in val_data:
            x, y = Variable(x).to(device), Variable(y).to(device)
            y_pred = generator(x)
            ssims.append(ssim(y_pred, y))
            psnrs.append(psnr(y_pred, y))

    return (
        torch.mean(torch.FloatTensor(ssims)),
        torch.mean(torch.FloatTensor(psnrs)),
    )


def train(
    input_dir: str,
    label_dir: str,
    generator: str,
    discriminator: str,
    l1_lambda: int = 50,
    num_epochs: int = 20,
):
    # Define generator.
    generator = GENERATORS[generator](3, 3).to(device)
    discriminator = DISCRIMINATORS[discriminator](3).to(device)

    # Define discriminator.

    # Loss fuctions. BCE for discriminator and L1 for generator.
    bce_loss = nn.BCEWithLogitsLoss().to(device)
    l1_loss = nn.L1Loss().to(device)

    # Optimizer. Initialized to be the same as the baseline.
    g_optimizer = optim.Adam(
        generator.parameters(),
        lr=2e-4,
        betas=(0.5, 0.999),
        eps=1e-07,
    )
    d_optimizer = optim.Adam(
        discriminator.parameters(),
        lr=2e-4,
        betas=(0.5, 0.999),
        eps=1e-07,
    )

    # Resize to 256 x 256 images.
    transform = transforms.Compose([
        transforms.Resize((256, 256), antialias=True),
        transforms.ConvertImageDtype(torch.float32),
    ])

    dataset = SplitImageDataset(
        input_dir,
        label_dir,
        batch_size=2,
        val_size=0.2,
        transform=transform,
    )

    for epoch in range(num_epochs):
        d_losses = []
        g_losses = []
        ssims = []
        psnrs = []

        for x, y in track(
            dataset.train,
            description=f"[{epoch+1}/{num_epochs}]",
            transient=True,
        ):
            x, y = Variable(x).to(device), Variable(y).to(device)

            generator.train()
            discriminator.train()

            # Discriminator training.
            discriminator.zero_grad(set_to_none=True)
            y_pred = generator(x)

            # The discriminator should predict all ones for "real" images, i.e.
            # images from the dataset.
            d_real_result = discriminator(x, y)
            d_real_loss = bce_loss(
                Variable(torch.ones(d_real_result.shape)).to(device),
                d_real_result,
            )

            # The discriminator should predict all zeros for "fake" images,
            # i.e. images generated by the generator.
            d_fake_result = discriminator(x, y_pred)
            d_fake_loss = bce_loss(
                Variable(torch.zeros(d_fake_result.shape)).to(device),
                d_fake_result,
            )

            # Loss of discriminator is the sum of the BCE losses of "real"
            # and "fake" data.
            d_loss = d_real_loss + d_fake_loss
            d_loss.backward()
            d_optimizer.step()

            # Generator training.
            generator.zero_grad(set_to_none=True)
            y_pred = generator(x)
            d_result = discriminator(x, y_pred).squeeze()

            # The training loss of the generator is a combination of how well
            # it was able to fool the discriminator (BCE) and how much it
            # resembles the real image (L1).
            g_loss = bce_loss(
                d_result,
                Variable(torch.ones(d_result.shape, device=device))
            ) + l1_lambda * l1_loss(y_pred, y)
            g_loss.backward()
            g_optimizer.step()

            # Keep track of loss and metrics.
            d_losses.append(d_loss.item())
            g_losses.append(g_loss.item())
            ssims.append(ssim(y_pred, y))
            psnrs.append(psnr(y_pred, y))

        val_ssim, val_psnr = validate(generator, dataset.validation)

        print("[%d/%d] d_loss: %.3f, g_loss: %.3f, ssim: %.3f, psnr: %.3f, val_ssim: %.3f, val_psnr: %.3f" % (
            epoch + 1,
            num_epochs,
            torch.mean(torch.FloatTensor(d_losses)),
            torch.mean(torch.FloatTensor(g_losses)),
            torch.mean(torch.FloatTensor(ssims)),
            torch.mean(torch.FloatTensor(psnrs)),
            val_ssim,
            val_psnr,
        ))
