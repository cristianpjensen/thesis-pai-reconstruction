import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
from tqdm import tqdm
from simple_term_menu import TerminalMenu
from pix2pix import (
    GeneratorEncoderDecoder,
    GeneratorUNet,
    PixelDiscriminator,
    Patch16Discriminator,
    Patch70Discriminator,
    Patch286Discriminator,
)
import utils


GENERATORS = {
    "Encoder-Decoder": GeneratorEncoderDecoder,
    "U-net": GeneratorUNet,
}

DISCRIMINATORS = {
    "PixelGAN": PixelDiscriminator,
    "PatchGAN 16x16": Patch16Discriminator,
    "PatchGAN 70x70": Patch70Discriminator,
    "PatchGAN 286x286": Patch286Discriminator,
}

INPUT_SIZE = 256
NUM_EPOCHS = 200
L1_LAMBDA = 100

if torch.cuda.is_available():
    print("Using CUDA device...\n")
    device = torch.device("cuda")
elif torch.backends.mps.is_available():
    print("Using MPS device...\n")
    device = torch.device("mps")
else:
    print("Using CPU device...\n")
    device = torch.device("cpu")


def main():
    generator_enum = list(GENERATORS.keys())
    menu = TerminalMenu(generator_enum, title="Generator")
    generator_model = generator_enum[menu.show()]
    print(generator_model)

    discriminator_enum = list(DISCRIMINATORS.keys())
    menu = TerminalMenu(discriminator_enum, title="\nDiscriminator")
    discriminator_model = discriminator_enum[menu.show()]
    print(discriminator_model, "\n")

    train_loader, val_loader = utils.load_dataset(
        "./data/maps/",
        ["train", "val"],
        INPUT_SIZE,
    )

    train(train_loader, val_loader, generator_model, discriminator_model)


def train(
    train_loader: torch.utils.data.DataLoader,
    val_loader: torch.utils.data.DataLoader,
    generator: str,
    discriminator: str,
):
    # Generator.
    generator = GENERATORS[generator](3, 3)
    generator.to(device)
    generator.train()

    # Discriminator.
    discriminator = DISCRIMINATORS[discriminator](3)
    discriminator.to(device)
    discriminator.train()

    # Loss fuctions. BCE for discriminator and L1 for generator.
    bce_loss = nn.BCELoss().to(device)
    l1_loss = nn.L1Loss().to(device)

    # Optimizer.
    g_optimizer = optim.Adam(generator.parameters())
    d_optimizer = optim.Adam(discriminator.parameters())

    # Get image size so all images have the same size. It is also used in
    # separating the input from the label image, since they are placed
    # horizontally next to each other. We assume the images are square.
    initial_datapoint = next(iter(train_loader))[0]
    img_size = initial_datapoint.shape[2]

    for epoch in range(NUM_EPOCHS):
        d_losses = []
        g_losses = []
        print(f"Epoch {epoch}")
        for xy_concat, _ in tqdm(train_loader):
            # Discriminator training.
            discriminator.zero_grad()

            # Separate input and label image. Left = input, right = label.
            x = xy_concat[:, :, :, :img_size].to(device)
            y = xy_concat[:, :, :, img_size:].to(device)

            x, y = Variable(x).to(device), Variable(y).to(device)
            y_pred = generator(x)

            # The discriminator should predict all ones for "real" images, i.e.
            # images from the dataset.
            d_real_result = discriminator(x, y)
            d_real_loss = bce_loss(
                d_real_result,
                Variable(torch.ones(d_real_result.shape)).to(device),
            )

            # The discriminator should predict all zeros for "fake" images,
            # i.e. images generated by the generator.
            d_fake_result = discriminator(x, y_pred)
            d_fake_loss = bce_loss(
                d_fake_result,
                Variable(torch.zeros(d_fake_result.shape)).to(device),
            )

            # Loss of discriminator is the average of the BCE losses of "real"
            # and "fake" data.
            d_loss = (d_real_loss + d_fake_loss) * 0.5
            d_loss.backward()
            d_optimizer.step()

            d_losses.append(d_loss.item())

            # Generator training.
            generator.zero_grad()

            y_pred = generator(x)
            d_result = discriminator(x, y_pred).squeeze()

            # The training loss of the generator is a combination of how well
            # it was able to fool the discriminator (BCE) and how much it
            # resembles the real image (L1).
            g_loss = bce_loss(
                d_result,
                Variable(torch.ones(d_result.size(), device=device))
            ) + L1_LAMBDA * l1_loss(y_pred, y)
            g_loss.backward()
            g_optimizer.step()

            g_losses.append(g_loss.item())

        print("[%d/%d] - d_loss: %.3f, g_loss: %.3f" % (
            epoch + 1,
            NUM_EPOCHS,
            torch.mean(torch.FloatTensor(d_losses)),
            torch.mean(torch.FloatTensor(g_losses)),
        ))


if __name__ == "__main__":
    main()
